version: '3.8'

services:
  # ------------------------------------
  # mcp-client 服务
  # ------------------------------------
  client:
    # 使用 build 指令，指定上下文为当前目录(.)，Dockerfile 为创建的 Dockerfile-client
    build:
      context: ./mcp-client
      dockerfile: Dockerfile
    container_name: mcp-client
    ports:
      # 将主机的 9009 端口映射到容器的 9009 端口
      # 格式： "主机端口:容器端口"
      - "9009:9009"
    volumes:
      # !!! 解决 ONNX 问题的关键 !!!
      # 挂载到 /app/models 子目录，避免覆盖 jar 文件
      # 模型文件会在: /app/models/model.onnx 和 /app/models/model.onnx_data
      # 
      # Windows 开发环境示例: - F:/study/java/2025/SpringAI-MCP-RAG-Dev:/app/models
      # Linux 部署环境使用: - /home/ubuntu/ai/models/qwen-embedding:/app/models
      - /home/ubuntu/ai/models/qwen-embedding:/app/models
    environment:
      # 指定模型文件路径
      - EMBEDDING_TOKENIZER_URL_PROD=file:/app/models/tokenizer.json
      - EMBEDDING_ONNX_MODEL_URL_PROD=file:/app/models/model.onnx
    # 如果需要加载环境变量文件，取消注释以下行（根据实际情况选择 .env 文件）
    env_file:
      - ./mcp-client/src/main/resources/.env
    #   或者
    #   - ./mcp-client/src/main/resources/.env_qwen
    restart: always
    networks:
      - springai

  # ------------------------------------
  # mcp-server 服务
  # ------------------------------------
  server:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    container_name: mcp-server
    ports:
      # 映射端口
      - "9060:9060"
    # (如果 mcp-server 也需要模型, 取消注释下面的 volumes 和 environment)
    # volumes:
    #   - /home/ubuntu/ai/models/qwen-embedding:/app
    env_file:
      - ./mcp-server/src/main/resources/.env
    restart: always
    networks:
      - springai
    depends_on:
      - client

  # ------------------------------------
  # frontend 前端服务
  # ------------------------------------
  frontend:
    build:
      # 使用相对路径（从当前 docker-compose.yml 所在目录计算）
      # 目录结构：study/java/2025/SpringAI-MCP-RAG-Dev -> study/vue/spring-ai-frontend-vue
      context: ../../../vue/spring-ai-frontend-vue
      dockerfile: Dockerfile.simple  # 简化版 - 使用服务器本地构建的 dist 目录
    container_name: spring-ai-frontend
    ports:
      # 将主机的 5500 端口映射到容器的 80 端口（nginx 默认端口）
      - "5500:80"
    restart: always
    networks:
      - springai
    depends_on:
      - client
      - server

networks:
  # 声明 'springai' 是一个外部网络
  # Docker Compose 不会尝试创建它，而是直接使用已存在的同名网络
  springai:
    external: true