version: '3.8'

services:
  # ------------------------------------
  # mcp-client 服务
  # ------------------------------------
  client:
    # 使用 build 指令，指定上下文为当前目录(.)，Dockerfile 为创建的 Dockerfile-client
    build:
      context: ./mcp-client
      dockerfile: Dockerfile
    container_name: mcp-client
    ports:
      # 将主机的 9009 端口映射到容器的 9009 端口
      # 格式： "主机端口:容器端口"
      - "9009:9009"
    volumes:
      # !!! 解决 ONNX 问题的关键 !!!
      # ...挂载到容器的 /app 目录 (即 Dockerfile 中定义的 WORKDIR)。
      # 当 Java 进程在 /app 目录启动时，它会发现 /app/model.onnx 和 /app/model.onnx_data
      # 这样就满足了 "model.onnx_data 需与 model.onnx 置于同一目录下" 且在 "运行 Boot 应用的目录中" 的要求。
      # 
      # Windows 开发环境示例: - F:/study/java/2025/SpringAI-MCP-RAG-Dev:/app
      # Linux 部署环境使用: - /home/ubuntu/ai/models/qwen-embedding:/app
      - /home/ubuntu/ai/models/qwen-embedding:/app
    restart: always
    networks:
      - springai

  # ------------------------------------
  # mcp-server 服务
  # ------------------------------------
  server:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    container_name: mcp-server
    ports:
      # 映射端口
      - "9060:9060"
    # (如果 mcp-server 也需要模型, 取消注释下面的 volumes 和 environment)
    # volumes:
    #   - /home/ubuntu/ai/models/qwen-embedding:/app
    # environment:
    #   - EMBEDDING_TOKENIZER_URL=file:/app/tokenizer.json
    #   - EMBEDDING_ONNX_MODEL_URL=file:/app/model.onnx
    restart: always
    networks:
      - springai
    depends_on:
      - client

  # ------------------------------------
  # frontend 前端服务
  # ------------------------------------
  frontend:
    build:
      # 使用相对路径（从当前 docker-compose.yml 所在目录计算）
      # 目录结构：study/java/2025/SpringAI-MCP-RAG-Dev -> study/vue/spring-ai-frontend-vue
      context: ../../../vue/spring-ai-frontend-vue
      dockerfile: Dockerfile.simple  # 简化版 - 使用服务器本地构建的 dist 目录
    container_name: spring-ai-frontend
    ports:
      # 将主机的 5500 端口映射到容器的 80 端口（nginx 默认端口）
      - "5500:80"
    restart: always
    networks:
      - springai
    depends_on:
      - client
      - server

networks:
  # 声明 'springai' 是一个外部网络
  # Docker Compose 不会尝试创建它，而是直接使用已存在的同名网络
  springai:
    external: true